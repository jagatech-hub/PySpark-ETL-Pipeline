{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pqjN0IL70AKF"
   },
   "outputs": [],
   "source": [
    "# OrderID ,CustomerID ,Product ,Quantity ,Price\n",
    "# 1001,C101,Widget A,10,25.50\n",
    "# 1002,C102,Widget B,5,18.75\n",
    "# 1003,C103,Widget A,8,25.50\n",
    "# 1004,C104,Widget C,12,30.00\n",
    "# 1005,C105,Widget B,3,18.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y3F4mCh10FFN"
   },
   "outputs": [],
   "source": [
    "# ETL\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "\n",
    "# Read CSV file into DataFrame\n",
    "file_path = \"data.csv\"\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Show the initial data\n",
    "df.show()\n",
    "\n",
    "# Calculate total order amount and add it as a new column\n",
    "df_with_total = df.withColumn(\"TotalOrderAmount\", col(\"Quantity\") * col(\"Price\"))\n",
    "\n",
    "# Show the transformed data\n",
    "df_with_total.show()\n",
    "\n",
    "# Define the path for the Delta Table\n",
    "delta_table_path = \"TotalOrderAmount\"\n",
    "\n",
    "# Write the transformed DataFrame to a Delta Table\n",
    "df_with_total.write.format(\"delta\").mode(\"overwrite\").save(delta_table_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QH3VS1Lq0yKl"
   },
   "outputs": [],
   "source": [
    "# Dockerization:\n",
    "# • Create a Dockerfile to package your PySpark script and dependencies.\n",
    "# • Build a Docker image.\n",
    "# • Run the ETL process inside a Docker container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8wT9SmGQ04wM"
   },
   "outputs": [],
   "source": [
    "# save the above etl file on py file etl.py file\n",
    "# Build the Docker Image: Open a terminal, navigate to etl.py file located, and build the Docker image using the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "32M9FdwT1HZr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KvOq79pR1BdL"
   },
   "outputs": [],
   "source": [
    "docker build -t etl-pyspark:latest ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oa5wfFE41R4g"
   },
   "outputs": [],
   "source": [
    "# How to run the docker file\n",
    "# TotalOrderAmount below is a mount point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pYA9E-9z1EdT"
   },
   "outputs": [],
   "source": [
    "docker run -v $(pwd)/TotalOrderAmount:/app/TotalOrderAmount etl-pyspark:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vvpFEk0b1ZC0"
   },
   "outputs": [],
   "source": [
    "  # Read Delta file from databricks lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9xWAUjA410GP"
   },
   "outputs": [],
   "source": [
    "# Path to the Delta table in Databricks\n",
    "delta_table_path = \"dbfs:/mnt/TotalOrderAmount/TotalOrderAmount_sample\"\n",
    "\n",
    "# Read the Delta table\n",
    "df = spark.read.format(\"delta\").load(delta_table_path)\n",
    "\n",
    "# Display the DataFrames\n",
    "Display(df)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
